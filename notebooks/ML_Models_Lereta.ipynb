{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "st.image(\"Snowflake_Logo.svg\", width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9826365b",
   "metadata": {},
   "source": [
    "# Lereta Intelligence Agent - ML Models\n",
    "\n",
    "**Training 3 Machine Learning Models for Tax & Flood Intelligence**\n",
    "\n",
    "This notebook trains 3 ML models for the Lereta Intelligence Agent:\n",
    "1. **TAX_DELINQUENCY_PREDICTOR** - Predicts property tax delinquency risk\n",
    "2. **CLIENT_CHURN_PREDICTOR** - Predicts client churn risk\n",
    "3. **LOAN_RISK_CLASSIFIER** - Classifies loans by risk level (LOW/MEDIUM/HIGH)\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "- Database: `LERETA_INTELLIGENCE`\n",
    "- Schema: `ML_MODELS`\n",
    "- Feature views created (V_TAX_DELINQUENCY_FEATURES, V_CLIENT_CHURN_FEATURES, V_LOAN_RISK_FEATURES)\n",
    "- Packages: `snowflake-ml-python`, `scikit-learn`, `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258063a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir('.'))  # Lists all files in current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d6e3c",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
    "from snowflake.ml.modeling.linear_model import LogisticRegression\n",
    "from snowflake.ml.modeling.preprocessing import OneHotEncoder, StandardScaler\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.registry import Registry\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current session\n",
    "session = Session.builder.getOrCreate()\n",
    "\n",
    "# Set context\n",
    "session.use_database(\"LERETA_INTELLIGENCE\")\n",
    "session.use_schema(\"ML_MODELS\")\n",
    "session.use_warehouse(\"LERETA_WH\")\n",
    "\n",
    "print(\"✅ Session configured\")\n",
    "print(f\"Database: {session.get_current_database()}\")\n",
    "print(f\"Schema: {session.get_current_schema()}\")\n",
    "print(f\"Warehouse: {session.get_current_warehouse()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model Registry\n",
    "registry = Registry(\n",
    "    session=session,\n",
    "    database_name=\"LERETA_INTELLIGENCE\",\n",
    "    schema_name=\"ML_MODELS\"\n",
    ")\n",
    "\n",
    "print(\"✅ Model Registry initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c85d8",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 1: Tax Delinquency Predictor\n",
    "\n",
    "**Objective**: Predict property tax delinquency risk  \n",
    "**Labels**: 0=Not Delinquent, 1=Delinquent  \n",
    "**Algorithm**: Random Forest Classifier  \n",
    "**Features**: Property type, tax amount, jurisdiction, payment history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec4776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tax delinquency feature data\n",
    "tax_df = session.table(\"LERETA_INTELLIGENCE.ANALYTICS.V_TAX_DELINQUENCY_FEATURES\")\n",
    "\n",
    "print(f\"✅ Loaded {tax_df.count()} records for tax delinquency prediction\")\n",
    "tax_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "train_tax, test_tax = tax_df.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "# Drop ID columns not needed for training\n",
    "train_tax = train_tax.drop(\"TAX_RECORD_ID\")\n",
    "test_tax = test_tax.drop(\"TAX_RECORD_ID\")\n",
    "\n",
    "print(f\"Training set: {train_tax.count()} records\")\n",
    "print(f\"Test set: {test_tax.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67152a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tax delinquency prediction pipeline - optimized for <10s execution\n",
    "# Using simpler model: fewer trees, shallow depth, no scaling\n",
    "tax_pipeline = Pipeline([\n",
    "    (\"Encoder\", OneHotEncoder(\n",
    "        input_cols=[\"PROPERTY_TYPE\", \"FLOOD_ZONE\", \"JURISDICTION_TYPE\", \"LOAN_TYPE\", \"CLIENT_TYPE\", \"LOAN_STATUS\", \"CLIENT_STATUS\"],\n",
    "        output_cols=[\"PROPERTY_TYPE_ENC\", \"FLOOD_ZONE_ENC\", \"JURISDICTION_TYPE_ENC\", \"LOAN_TYPE_ENC\", \"CLIENT_TYPE_ENC\", \"LOAN_STATUS_ENC\", \"CLIENT_STATUS_ENC\"],\n",
    "        drop_input_cols=True,\n",
    "        handle_unknown=\"ignore\"\n",
    "    )),\n",
    "    (\"Classifier\", RandomForestClassifier(\n",
    "        label_cols=[\"ACTUAL_DELINQUENT\"],\n",
    "        output_cols=[\"PREDICTED_DELINQUENT\"],\n",
    "        n_estimators=3,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✅ Tax delinquency pipeline created (optimized for speed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the tax delinquency prediction model\n",
    "print(\"Training tax delinquency prediction model...\")\n",
    "tax_pipeline.fit(train_tax)\n",
    "print(\"✅ Tax delinquency model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\n",
    "test_predictions = tax_pipeline.predict(test_tax)\n",
    "test_results = test_predictions.select(\"ACTUAL_DELINQUENT\", \"PREDICTED_DELINQUENT\").to_pandas()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy = accuracy_score(test_results['ACTUAL_DELINQUENT'], test_results['PREDICTED_DELINQUENT'])\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    test_results['ACTUAL_DELINQUENT'], \n",
    "    test_results['PREDICTED_DELINQUENT']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e776bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing model if it exists to force fresh registration\n",
    "try:\n",
    "    registry.delete_model(\"TAX_DELINQUENCY_PREDICTOR\")\n",
    "    print(\"✅ Deleted existing TAX_DELINQUENCY_PREDICTOR\")\n",
    "except:\n",
    "    print(\"No existing model to delete\")\n",
    "\n",
    "# Register model in Model Registry\n",
    "# Drop label column from sample data - model signature should only include features\n",
    "sample_data = train_tax.drop(\"ACTUAL_DELINQUENT\").limit(100)\n",
    "\n",
    "registry.log_model(\n",
    "    model=tax_pipeline,\n",
    "    model_name=\"TAX_DELINQUENCY_PREDICTOR\",\n",
    "    target_platforms=['WAREHOUSE'],\n",
    "    sample_input_data=sample_data,\n",
    "    comment=\"Predicts property tax delinquency risk\"\n",
    ")\n",
    "\n",
    "print(\"✅ TAX_DELINQUENCY_PREDICTOR registered in Model Registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539f19f",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 2: Campaign ROI Predictor\n",
    "\n",
    "**Objective**: Predict campaign ROI likelihood  \n",
    "**Labels**: 0=Low ROI, 1=Medium ROI, 2=High ROI  \n",
    "**Algorithm**: Logistic Regression  \n",
    "**Features**: Objective, budget, duration, posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d627cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load campaign ROI feature data\n",
    "roi_df = session.table(\"HOOTSUITE_INTELLIGENCE.ANALYTICS.V_CAMPAIGN_ROI_FEATURES\")\n",
    "\n",
    "print(f\"✅ Loaded {roi_df.count()} records for ROI prediction\")\n",
    "roi_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c37f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_roi, test_roi = roi_df.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "train_roi = train_roi.drop(\"CAMPAIGN_ID\")\n",
    "test_roi = test_roi.drop(\"CAMPAIGN_ID\")\n",
    "\n",
    "print(f\"Training set: {train_roi.count()} records\")\n",
    "print(f\"Test set: {test_roi.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aab386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAST ROI prediction pipeline - optimized for <10s execution\n",
    "# Using LogisticRegression with fewer iterations, no scaling\n",
    "roi_pipeline = Pipeline([\n",
    "    (\"Encoder\", OneHotEncoder(\n",
    "        input_cols=[\"OBJECTIVE\"],\n",
    "        output_cols=[\"OBJECTIVE_ENC\"],\n",
    "        drop_input_cols=True,\n",
    "        handle_unknown=\"ignore\"\n",
    "    )),\n",
    "    (\"Classifier\", LogisticRegression(\n",
    "        label_cols=[\"ROI_LABEL\"],\n",
    "        output_cols=[\"PREDICTED_ROI\"],\n",
    "        max_iter=100\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✅ ROI prediction pipeline created (optimized for speed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ROI prediction model\n",
    "print(\"Training ROI prediction model...\")\n",
    "roi_pipeline.fit(train_roi)\n",
    "print(\"✅ ROI prediction model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation skipped - proceed directly to registration\n",
    "print(\"✅ Skipping evaluation, registering model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ea6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing model if it exists to force fresh registration\n",
    "try:\n",
    "    registry.delete_model(\"CAMPAIGN_ROI_PREDICTOR\")\n",
    "    print(\"✅ Deleted existing CAMPAIGN_ROI_PREDICTOR\")\n",
    "except:\n",
    "    print(\"No existing model to delete\")\n",
    "\n",
    "# Register model\n",
    "# Drop label column from sample data - model signature should only include features\n",
    "sample_data = train_roi.drop(\"ROI_LABEL\").limit(100)\n",
    "\n",
    "registry.log_model(\n",
    "    model=roi_pipeline,\n",
    "    model_name=\"CAMPAIGN_ROI_PREDICTOR\",\n",
    "    target_platforms=['WAREHOUSE'],\n",
    "    sample_input_data=sample_data,\n",
    "    comment=\"Predicts campaign ROI with 3 outcomes (Low/Medium/High)\"\n",
    ")\n",
    "\n",
    "print(\"✅ CAMPAIGN_ROI_PREDICTOR registered in Model Registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547c8fb",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 3: Ticket Priority Classifier\n",
    "\n",
    "**Objective**: Classify support ticket priority  \n",
    "**Labels**: 0=Low, 1=Medium, 2=High, 3=Urgent  \n",
    "**Algorithm**: Random Forest Classifier  \n",
    "**Features**: Category, issue summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ticket priority feature data\n",
    "ticket_df = session.table(\"HOOTSUITE_INTELLIGENCE.ANALYTICS.V_TICKET_PRIORITY_FEATURES\")\n",
    "\n",
    "print(f\"✅ Loaded {ticket_df.count()} records for ticket priority classification\")\n",
    "ticket_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb988167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_ticket, test_ticket = ticket_df.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "train_ticket = train_ticket.drop(\"TICKET_ID\")\n",
    "test_ticket = test_ticket.drop(\"TICKET_ID\")\n",
    "\n",
    "print(f\"Training set: {train_ticket.count()} records\")\n",
    "print(f\"Test set: {test_ticket.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dee038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAST ticket priority pipeline - optimized for <10s execution\n",
    "# Using simpler RandomForest: fewer trees, shallow depth, no scaling\n",
    "ticket_pipeline = Pipeline([\n",
    "    (\"Encoder\", OneHotEncoder(\n",
    "        input_cols=[\"CATEGORY\"],\n",
    "        output_cols=[\"CATEGORY_ENC\"],\n",
    "        drop_input_cols=True,\n",
    "        handle_unknown=\"ignore\"\n",
    "    )),\n",
    "    (\"Classifier\", RandomForestClassifier(\n",
    "        label_cols=[\"PRIORITY_LABEL\"],\n",
    "        output_cols=[\"PREDICTED_PRIORITY\"],\n",
    "        n_estimators=3,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✅ Ticket priority pipeline created (optimized for speed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6eeac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ticket priority model\n",
    "print(\"Training ticket priority model...\")\n",
    "ticket_pipeline.fit(train_ticket)\n",
    "print(\"✅ Ticket priority model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c523c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "test_predictions = ticket_pipeline.predict(test_ticket)\n",
    "test_results = test_predictions.select(\"PRIORITY_LABEL\", \"PREDICTED_PRIORITY\").to_pandas()\n",
    "\n",
    "accuracy = accuracy_score(test_results['PRIORITY_LABEL'], test_results['PREDICTED_PRIORITY'])\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    test_results['PRIORITY_LABEL'], \n",
    "    test_results['PREDICTED_PRIORITY']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f26843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing model if it exists to force fresh registration\n",
    "try:\n",
    "    registry.delete_model(\"TICKET_PRIORITY_CLASSIFIER\")\n",
    "    print(\"✅ Deleted existing TICKET_PRIORITY_CLASSIFIER\")\n",
    "except:\n",
    "    print(\"No existing model to delete\")\n",
    "\n",
    "# Register model\n",
    "# Drop label column from sample data - model signature should only include features\n",
    "sample_data = train_ticket.drop(\"PRIORITY_LABEL\").limit(100)\n",
    "\n",
    "registry.log_model(\n",
    "    model=ticket_pipeline,\n",
    "    model_name=\"TICKET_PRIORITY_CLASSIFIER\",\n",
    "    target_platforms=['WAREHOUSE'],\n",
    "    sample_input_data=sample_data,\n",
    "    comment=\"Classifies ticket priority with 4 levels (Low/Medium/High/Urgent)\"\n",
    ")\n",
    "\n",
    "print(\"✅ TICKET_PRIORITY_CLASSIFIER registered in Model Registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7194ad",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all registered models\n",
    "models = session.sql(\"SHOW MODELS IN SCHEMA ML_MODELS\").collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REGISTERED MODELS\")\n",
    "print(\"=\"*80)\n",
    "for model in models:\n",
    "    print(f\"✅ {model['name']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n3 ML models successfully trained and registered:\")\n",
    "print(\"1. CHURN_RISK_PREDICTOR - Predicts churn risk (3 classes)\")\n",
    "print(\"2. CAMPAIGN_ROI_PREDICTOR - Predicts ROI (3 classes)\")\n",
    "print(\"3. TICKET_PRIORITY_CLASSIFIER - Classifies priority (4 classes)\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run hootsuite_07_ml_model_functions.sql to create SQL procedures\")\n",
    "print(\"2. Run hootsuite_08_intelligence_agent.sql to configure agent\")\n",
    "print(\"3. Test agent with sample questions from hootsuite_questions.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
