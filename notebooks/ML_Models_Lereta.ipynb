{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "st.image(\"Snowflake_Logo.svg\", width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9826365b",
   "metadata": {},
   "source": [
    "# Lereta Intelligence Agent - ML Models\n",
    "\n",
    "**Training 3 Machine Learning Models for Tax & Flood Intelligence**\n",
    "\n",
    "This notebook trains 3 ML models for the Lereta Intelligence Agent:\n",
    "1. **TAX_DELINQUENCY_PREDICTOR** - Predicts property tax delinquency risk\n",
    "2. **CLIENT_CHURN_PREDICTOR** - Predicts client churn risk\n",
    "3. **LOAN_RISK_CLASSIFIER** - Classifies loans by risk level (LOW/MEDIUM/HIGH)\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "- Database: `LERETA_INTELLIGENCE`\n",
    "- Schema: `ML_MODELS`\n",
    "- Feature views created (V_TAX_DELINQUENCY_FEATURES, V_CLIENT_CHURN_FEATURES, V_LOAN_RISK_FEATURES)\n",
    "- Packages: `snowflake-ml-python`, `scikit-learn`, `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258063a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir('.'))  # Lists all files in current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d6e3c",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.modeling.preprocessing import OneHotEncoder\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.registry import Registry\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current session\n",
    "session = Session.builder.getOrCreate()\n",
    "\n",
    "# Set context\n",
    "session.use_database(\"LERETA_INTELLIGENCE\")\n",
    "session.use_schema(\"ML_MODELS\")\n",
    "session.use_warehouse(\"LERETA_WH\")\n",
    "\n",
    "print(\"✅ Session configured\")\n",
    "print(f\"Database: {session.get_current_database()}\")\n",
    "print(f\"Schema: {session.get_current_schema()}\")\n",
    "print(f\"Warehouse: {session.get_current_warehouse()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model Registry\n",
    "registry = Registry(\n",
    "    session=session,\n",
    "    database_name=\"LERETA_INTELLIGENCE\",\n",
    "    schema_name=\"ML_MODELS\"\n",
    ")\n",
    "\n",
    "print(\"✅ Model Registry initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c85d8",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 1: Tax Delinquency Predictor\n",
    "\n",
    "**Objective**: Predict property tax delinquency risk  \n",
    "**Labels**: 0=Not Delinquent, 1=Delinquent  \n",
    "**Algorithm**: Random Forest Classifier  \n",
    "**Features**: Property type, tax amount, jurisdiction, payment history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec4776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tax delinquency feature data\n",
    "tax_df = session.table(\"LERETA_INTELLIGENCE.ANALYTICS.V_TAX_DELINQUENCY_FEATURES\")\n",
    "\n",
    "print(f\"✅ Loaded {tax_df.count()} records for tax delinquency prediction\")\n",
    "tax_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "train_tax, test_tax = tax_df.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "# Drop ID columns not needed for training\n",
    "train_tax = train_tax.drop(\"TAX_RECORD_ID\")\n",
    "test_tax = test_tax.drop(\"TAX_RECORD_ID\")\n",
    "\n",
    "print(f\"Training set: {train_tax.count()} records\")\n",
    "print(f\"Test set: {test_tax.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67152a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tax delinquency prediction pipeline - optimized for <10s execution\n",
    "# Using simpler model: fewer trees, shallow depth, no scaling\n",
    "tax_pipeline = Pipeline([\n",
    "    (\"Encoder\", OneHotEncoder(\n",
    "        input_cols=[\"PROPERTY_TYPE\", \"FLOOD_ZONE\", \"JURISDICTION_TYPE\", \"LOAN_TYPE\", \"CLIENT_TYPE\", \"LOAN_STATUS\", \"CLIENT_STATUS\"],\n",
    "        output_cols=[\"PROPERTY_TYPE_ENC\", \"FLOOD_ZONE_ENC\", \"JURISDICTION_TYPE_ENC\", \"LOAN_TYPE_ENC\", \"CLIENT_TYPE_ENC\", \"LOAN_STATUS_ENC\", \"CLIENT_STATUS_ENC\"],\n",
    "        drop_input_cols=True,\n",
    "        handle_unknown=\"ignore\"\n",
    "    )),\n",
    "    (\"Classifier\", RandomForestClassifier(\n",
    "        label_cols=[\"ACTUAL_DELINQUENT\"],\n",
    "        output_cols=[\"PREDICTED_DELINQUENT\"],\n",
    "        n_estimators=3,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✅ Tax delinquency pipeline created (optimized for speed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the tax delinquency prediction model\n",
    "print(\"Training tax delinquency prediction model...\")\n",
    "tax_pipeline.fit(train_tax)\n",
    "print(\"✅ Tax delinquency model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\n",
    "test_predictions = tax_pipeline.predict(test_tax)\n",
    "test_results = test_predictions.select(\"ACTUAL_DELINQUENT\", \"PREDICTED_DELINQUENT\").to_pandas()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy = accuracy_score(test_results['ACTUAL_DELINQUENT'], test_results['PREDICTED_DELINQUENT'])\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    test_results['ACTUAL_DELINQUENT'], \n",
    "    test_results['PREDICTED_DELINQUENT']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e776bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing model if it exists to force fresh registration\n",
    "try:\n",
    "    registry.delete_model(\"TAX_DELINQUENCY_PREDICTOR\")\n",
    "    print(\"✅ Deleted existing TAX_DELINQUENCY_PREDICTOR\")\n",
    "except:\n",
    "    print(\"No existing model to delete\")\n",
    "\n",
    "# Register model in Model Registry\n",
    "# Drop label column from sample data - model signature should only include features\n",
    "sample_data = train_tax.drop(\"ACTUAL_DELINQUENT\").limit(100)\n",
    "\n",
    "registry.log_model(\n",
    "    model=tax_pipeline,\n",
    "    model_name=\"TAX_DELINQUENCY_PREDICTOR\",\n",
    "    target_platforms=['WAREHOUSE'],\n",
    "    sample_input_data=sample_data,\n",
    "    comment=\"Predicts property tax delinquency risk\"\n",
    ")\n",
    "\n",
    "print(\"✅ TAX_DELINQUENCY_PREDICTOR registered in Model Registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539f19f",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 2: Client Churn Predictor\n",
    "\n",
    "**Objective**: Predict client subscription status  \n",
    "**Labels**: ACTIVE, EXPIRED, PENDING_RENEWAL  \n",
    "**Algorithm**: XGBoost Classifier  \n",
    "**Features**: Client type, subscription tier, support metrics, revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d627cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load client churn feature data\n",
    "churn_df = session.table(\"LERETA_INTELLIGENCE.ANALYTICS.V_CLIENT_CHURN_FEATURES\")\n",
    "\n",
    "print(f\"✅ Loaded {churn_df.count()} records for client churn prediction\")\n",
    "churn_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c37f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_churn, test_churn = churn_df.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "train_churn = train_churn.drop(\"CLIENT_ID\")\n",
    "test_churn = test_churn.drop(\"CLIENT_ID\")\n",
    "\n",
    "print(f\"Training set: {train_churn.count()} records\")\n",
    "print(f\"Test set: {test_churn.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aab386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client churn prediction pipeline - optimized for speed\n",
    "churn_pipeline = Pipeline([\n",
    "    (\"Encoder\", OneHotEncoder(\n",
    "        input_cols=[\"CLIENT_TYPE\", \"SERVICE_TYPE\", \"SUBSCRIPTION_TIER\", \"BILLING_CYCLE\"],\n",
    "        output_cols=[\"CLIENT_TYPE_ENC\", \"SERVICE_TYPE_ENC\", \"SUBSCRIPTION_TIER_ENC\", \"BILLING_CYCLE_ENC\"],\n",
    "        drop_input_cols=True,\n",
    "        handle_unknown=\"ignore\"\n",
    "    )),\n",
    "    (\"Classifier\", XGBClassifier(\n",
    "        label_cols=[\"CHURN_RISK_LABEL\"],\n",
    "        output_cols=[\"PREDICTED_RISK\"],\n",
    "        n_estimators=3,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✅ Client churn pipeline created (optimized for speed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the client churn prediction model\n",
    "print(\"Training client churn prediction model...\")\n",
    "churn_pipeline.fit(train_churn)\n",
    "print(\"✅ Client churn model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation skipped - proceed directly to registration\n",
    "print(\"✅ Skipping evaluation, registering model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ea6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing model if it exists\n",
    "try:\n",
    "    registry.delete_model(\"CLIENT_CHURN_PREDICTOR\")\n",
    "    print(\"✅ Deleted existing CLIENT_CHURN_PREDICTOR\")\n",
    "except:\n",
    "    print(\"No existing model to delete\")\n",
    "\n",
    "# Register model\n",
    "# Drop label column from sample data\n",
    "sample_data = train_churn.drop(\"CHURN_RISK_LABEL\").limit(100)\n",
    "\n",
    "registry.log_model(\n",
    "    model=churn_pipeline,\n",
    "    model_name=\"CLIENT_CHURN_PREDICTOR\",\n",
    "    target_platforms=['WAREHOUSE'],\n",
    "    sample_input_data=sample_data,\n",
    "    comment=\"Predicts client churn risk (0=Low, 1=Medium, 2=High)\"\n",
    ")\n",
    "\n",
    "print(\"✅ CLIENT_CHURN_PREDICTOR registered in Model Registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547c8fb",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 3: Loan Risk Classifier\n",
    "\n",
    "**Objective**: Classify loan risk level  \n",
    "**Labels**: LOW, MEDIUM, HIGH  \n",
    "**Algorithm**: Random Forest Classifier  \n",
    "**Features**: Loan details, flood zone, tax compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load loan risk feature data\n",
    "risk_df = session.table(\"LERETA_INTELLIGENCE.ANALYTICS.V_LOAN_RISK_FEATURES\")\n",
    "\n",
    "print(f\"✅ Loaded {risk_df.count()} records for loan risk classification\")\n",
    "risk_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb988167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_risk, test_risk = risk_df.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "train_risk = train_risk.drop(\"LOAN_ID\")\n",
    "test_risk = test_risk.drop(\"LOAN_ID\")\n",
    "\n",
    "print(f\"Training set: {train_risk.count()} records\")\n",
    "print(f\"Test set: {test_risk.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dee038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loan risk classification pipeline - optimized for speed\n",
    "risk_pipeline = Pipeline([\n",
    "    (\"Encoder\", OneHotEncoder(\n",
    "        input_cols=[\"LOAN_TYPE\", \"LOAN_STATUS\", \"PROPERTY_TYPE\", \"FLOOD_ZONE\", \"PROPERTY_STATE\", \"JURISDICTION_TYPE\", \"CLIENT_TYPE\"],\n",
    "        output_cols=[\"LOAN_TYPE_ENC\", \"LOAN_STATUS_ENC\", \"PROPERTY_TYPE_ENC\", \"FLOOD_ZONE_ENC\", \"PROPERTY_STATE_ENC\", \"JURISDICTION_TYPE_ENC\", \"CLIENT_TYPE_ENC\"],\n",
    "        drop_input_cols=True,\n",
    "        handle_unknown=\"ignore\"\n",
    "    )),\n",
    "    (\"Classifier\", RandomForestClassifier(\n",
    "        label_cols=[\"RISK_LEVEL\"],\n",
    "        output_cols=[\"PREDICTED_RISK\"],\n",
    "        n_estimators=3,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✅ Loan risk pipeline created (optimized for speed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6eeac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the loan risk classification model\n",
    "print(\"Training loan risk classification model...\")\n",
    "risk_pipeline.fit(train_risk)\n",
    "print(\"✅ Loan risk model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c523c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "test_predictions = risk_pipeline.predict(test_risk)\n",
    "test_results = test_predictions.select(\"RISK_LEVEL\", \"PREDICTED_RISK\").to_pandas()\n",
    "\n",
    "accuracy = accuracy_score(test_results['RISK_LEVEL'], test_results['PREDICTED_RISK'])\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    test_results['RISK_LEVEL'], \n",
    "    test_results['PREDICTED_RISK']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f26843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing model if it exists\n",
    "try:\n",
    "    registry.delete_model(\"LOAN_RISK_CLASSIFIER\")\n",
    "    print(\"✅ Deleted existing LOAN_RISK_CLASSIFIER\")\n",
    "except:\n",
    "    print(\"No existing model to delete\")\n",
    "\n",
    "# Register model\n",
    "# Drop label column from sample data\n",
    "sample_data = train_risk.drop(\"RISK_LEVEL\").limit(100)\n",
    "\n",
    "registry.log_model(\n",
    "    model=risk_pipeline,\n",
    "    model_name=\"LOAN_RISK_CLASSIFIER\",\n",
    "    target_platforms=['WAREHOUSE'],\n",
    "    sample_input_data=sample_data,\n",
    "    comment=\"Classifies loans by risk level (LOW/MEDIUM/HIGH)\"\n",
    ")\n",
    "\n",
    "print(\"✅ LOAN_RISK_CLASSIFIER registered in Model Registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7194ad",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all registered models\n",
    "models = session.sql(\"SHOW MODELS IN SCHEMA ML_MODELS\").collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REGISTERED MODELS\")\n",
    "print(\"=\"*80)\n",
    "for model in models:\n",
    "    print(f\"✅ {model['name']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n3 ML models successfully trained and registered:\")\n",
    "print(\"1. TAX_DELINQUENCY_PREDICTOR - Predicts tax delinquency risk\")\n",
    "print(\"2. CLIENT_CHURN_PREDICTOR - Predicts client churn risk\")\n",
    "print(\"3. LOAN_RISK_CLASSIFIER - Classifies loan risk level\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run sql/ml/07_ml_model_wrappers.sql to create SQL functions\")\n",
    "print(\"2. Run sql/agent/08_create_ai_agent.sql to configure agent\")\n",
    "print(\"3. Test agent with sample questions from docs/questions.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
